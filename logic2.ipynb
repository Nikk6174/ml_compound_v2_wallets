{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc628c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import libraries and set up path to custom utilities\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the 'scripts' directory to the Python path to find our utility module\n",
    "# This makes the import robust, regardless of where the notebook is run from.\n",
    "sys.path.append(os.path.abspath('scripts'))\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom functions from the risk_utils module\n",
    "try:\n",
    "    from risk_utils import (\n",
    "        load_and_preprocess_data,\n",
    "        create_advanced_wallet_features,\n",
    "        calculate_advanced_risk_score,\n",
    "        apply_ml_refinements,\n",
    "        calculate_final_risk_score\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"FATAL ERROR: Could not import from 'risk_utils.py'.\")\n",
    "    print(\"Please ensure 'scripts/risk_utils.py' exists in your project directory.\")\n",
    "    # Exit or handle error appropriately\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717dfa4b",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### **Markdown: Feature Engineering Logic**\n",
    "\n",
    "The `create_advanced_wallet_features` function aggregates transaction data to a wallet level. Below are the formulas for some of the key engineered features that serve as risk indicators:\n",
    "\n",
    "- **Send/Receive Ratio (`send_receive_ratio`)**: Measures the ratio of outgoing to incoming transactions. A highly imbalanced ratio can be a risk indicator.  \n",
    "  $$\n",
    "  \\text{Send/Receive Ratio}\n",
    "  =\n",
    "  \\frac{\\text{Total Sent Transactions}}\n",
    "       {\\max(\\text{Total Received Transactions}, 1)}\n",
    "  $$\n",
    "\n",
    "- **Transaction Frequency (`transaction_frequency`)**: Calculates the average number of transactions per day over the wallet’s active lifespan. High frequency can indicate bot activity.  \n",
    "  $$\n",
    "  \\text{Transaction Frequency}\n",
    "  =\n",
    "  \\frac{\\text{Total Transactions}}\n",
    "       {\\max(\\text{Activity Span in Days}, 1)}\n",
    "  $$\n",
    "\n",
    "- **Contract Complexity (`contract_complexity`)**: Assesses the diversity of a wallet’s interactions. A low value (near 0) means the wallet repeatedly calls the same function; a high value (near 1) indicates interaction with many different functions.\n",
    "\n",
    "  First compute the Dominant Function Ratio:\n",
    "  $$\n",
    "  \\text{Dominant Function Ratio}\n",
    "  =\n",
    "  \\frac{\\text{Count of Most Common Function}}\n",
    "       {\\text{Total Transactions}}\n",
    "  $$\n",
    "\n",
    "  Then:\n",
    "  $$\n",
    "  \\text{Contract Complexity}\n",
    "  = \n",
    "  1 \\;-\\; \\text{Dominant Function Ratio}\n",
    "  $$\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "361d446d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data/compound_v2_v3_transactions.csv\n",
      "Processing features for 80 wallets using 'wallet_address' as identifier...\n",
      "...feature engineering complete.\n",
      "Calculating advanced risk scores...\n",
      "...base risk score calculation complete.\n",
      "Applying ML refinements (Anomaly Detection and Clustering)...\n",
      "...identified 4 anomalous wallets.\n",
      "...clustered wallets into 5 groups.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Run the Full Risk Scoring Pipeline\n",
    "def run_pipeline(filepath='data/compound_v2_v3_transactions.csv'):\n",
    "    \"\"\"Executes the entire risk scoring process from loading data to saving the output.\"\"\"\n",
    "    \n",
    "    # Step 1: Load and preprocess data\n",
    "    df_processed = load_and_preprocess_data(filepath)\n",
    "    if df_processed.empty:\n",
    "        print(\"Stopping execution due to missing data file.\")\n",
    "        return None\n",
    "\n",
    "    # Step 2: Create wallet-level features\n",
    "    wallet_df = create_advanced_wallet_features(df_processed)\n",
    "    wallet_df = wallet_df.fillna(0) # Fill NaNs from std dev etc.\n",
    "\n",
    "    # Step 3: Calculate the base risk score\n",
    "    wallet_df['base_risk_score'] = calculate_advanced_risk_score(wallet_df)\n",
    "\n",
    "    # Step 4: Apply ML-based refinements (anomaly detection & clustering)\n",
    "    wallet_df = apply_ml_refinements(wallet_df)\n",
    "\n",
    "    # Step 5: Calculate the final, adjusted risk score\n",
    "    wallet_df['final_risk_score'] = calculate_final_risk_score(wallet_df)\n",
    "\n",
    "    # Step 6: Categorize risk for reporting\n",
    "    def categorize_risk(score):\n",
    "        if score < 200: return 'Very Low'\n",
    "        elif score < 400: return 'Low'\n",
    "        elif score < 600: return 'Medium'\n",
    "        elif score < 800: return 'High'\n",
    "        else: return 'Very High'\n",
    "    wallet_df['risk_category'] = wallet_df['final_risk_score'].apply(categorize_risk)\n",
    "    \n",
    "    return wallet_df\n",
    "\n",
    "# Execute the pipeline\n",
    "wallet_risk_data = run_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7b326",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e80548d",
   "metadata": {},
   "source": [
    "### **Markdown: Base Risk Score Calculation**\n",
    "\n",
    "The `calculate_advanced_risk_score` function uses a weighted component model.\n",
    "\n",
    "1.  **Normalization**: First, all feature values are normalized to a common scale of [0, 1] using Min-Max Scaling. This prevents features with large ranges from dominating the score.\n",
    "    $$\n",
    "    X_{\\text{norm}} = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n",
    "    $$\n",
    "\n",
    "2.  **Component Score**: Features are grouped into logical risk components (e.g., `volume_risk`, `behavioral_risk`). The score for each component is the average of its normalized feature values.\n",
    "    $$\n",
    "    C_i = \\frac{1}{N} \\sum_{j=1}^{N} F_{j, \\text{norm}}\n",
    "    $$\n",
    "    where $C_i$ is the score for component $i$, and $F_j$ are the $N$ features within that component.\n",
    "\n",
    "3.  **Weighted Sum**: The base score is the sum of all component scores, each multiplied by its predefined weight ($w_i$).\n",
    "    $$\n",
    "    \\text{Score}_{\\text{base}} = \\sum_{i=1}^{n} (w_i \\cdot C_i)\n",
    "    $$\n",
    "\n",
    "4.  **Penalty Adjustments**: Finally, penalties are applied to wallets exhibiting specific high-risk behaviors (e.g., high error rate), multiplying their score by a penalty factor.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff635b0d",
   "metadata": {},
   "source": [
    "### **Markdown: ML Refinements & Final Score**\n",
    "\n",
    "The `apply_ml_refinements` and `calculate_final_risk_score` functions adjust the base score using unsupervised learning.\n",
    "\n",
    "1.  **Anomaly Detection (Isolation Forest)**: This model identifies wallets that are statistical outliers based on their feature combinations. These are flagged as `is_anomaly = True`.\n",
    "\n",
    "2.  **Clustering (K-Means)**: This model groups wallets into behavioral clusters. We then calculate a risk adjustment factor for each cluster based on its average risk relative to the global average.\n",
    "    $$\n",
    "    \\text{Adjustment}_{\\text{cluster}} = \\frac{\\text{Mean Score}_{\\text{cluster}}}{\\text{Mean Score}_{\\text{global}}}\n",
    "    $$\n",
    "\n",
    "3.  **Final Score Calculation**: The final score combines the base score with the ML refinements. A significant penalty (boost) is applied to anomalies, and the cluster adjustment is then applied.\n",
    "    $$\n",
    "    \\text{Score}_{\\text{final}} = \\text{Score}_{\\text{base}} \\times (\\text{Anomaly Boost if True else 1}) \\times \\text{Adjustment}_{\\text{cluster}}\n",
    "    $$\n",
    "    The final score is then capped between 0 and 1000.\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7799b81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RESULTS ===\n",
      "Total wallets analyzed: 80\n",
      "Average risk score: 128\n",
      "\n",
      "Top 5 highest risk wallets:\n",
      "                                     wallet_id  score\n",
      "0   0x0039f22efb07a647557c7c5d17854cfd6d489ef3   1000\n",
      "39  0x70d8e4ab175dfe0eab4e9a7f33e0a2d19f44001e   1000\n",
      "23  0x4814be124d7fe3b240eb46061f7ddfab468fe122   1000\n",
      "22  0x427f2ac5fdf4245e027d767e7c3ac272a1f40a65   1000\n",
      "57  0xa7f3c74f0255796fd5d3ddcf88db769f7a6bf46a    793\n",
      "\n",
      "Risk category distribution:\n",
      "risk_category\n",
      "Very Low     71\n",
      "Very High     4\n",
      "High          4\n",
      "Medium        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ wallet_risk_scores.csv saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Final Output and Summary\n",
    "if wallet_risk_data is not None:\n",
    "    # Create and save the final output file as required\n",
    "    output_df = wallet_risk_data[['wallet_id', 'final_risk_score']].copy()\n",
    "    output_df.columns = ['wallet_id', 'score']\n",
    "    output_df = output_df.sort_values('score', ascending=False)\n",
    "    output_df.to_csv('wallet_risk_scores.csv', index=False)\n",
    "\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Total wallets analyzed: {len(output_df)}\")\n",
    "    print(f\"Average risk score: {output_df['score'].mean():.0f}\")\n",
    "    print(\"\\nTop 5 highest risk wallets:\")\n",
    "    print(output_df.head(5))\n",
    "    print(\"\\nRisk category distribution:\")\n",
    "    print(wallet_risk_data['risk_category'].value_counts())\n",
    "    print(\"\\n✓ wallet_risk_scores.csv saved successfully.\")\n",
    "else:\n",
    "    print(\"\\nPipeline did not complete. No output file was generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9538c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c870d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc2a5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137bb192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f5f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fdc51c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26e14ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf23fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7477c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2def5ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbc285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3b758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c605ca9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
