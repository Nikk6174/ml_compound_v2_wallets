{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e266a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf9f46",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data (Simplified from EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c0da9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n",
      "Data loaded. Shape: (277, 14)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_preprocess_data(filepath):\n",
    "    \"\"\"Loads and performs basic cleaning and type conversion.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {filepath} not found.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    relevant_columns = ['from', 'to', 'value', 'gas', 'gasPrice', 'gasUsed',\n",
    "                        'timeStamp', 'isError', 'txreceipt_status', 'functionName',\n",
    "                        'wallet_address', 'protocol_version', 'methodId', 'blockNumber']\n",
    "    existing_columns = [col for col in relevant_columns if col in df.columns]\n",
    "    df_clean = df[existing_columns].copy()\n",
    "\n",
    "    \n",
    "    if 'timeStamp' in df_clean.columns:\n",
    "        df_clean['timeStamp'] = pd.to_datetime(df_clean['timeStamp'], unit='s')\n",
    "    if 'value' in df_clean.columns:\n",
    "        df_clean['value'] = pd.to_numeric(df_clean['value'], errors='coerce')\n",
    "    # Fill categorical NaNs\n",
    "    for col in ['functionName', 'protocol_version']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = df_clean[col].fillna('unknown')\n",
    "    # Fill other NaNs and convert types\n",
    "    if 'methodId' in df_clean.columns:\n",
    "        df_clean['methodId'] = df_clean['methodId'].fillna('0x00000000')\n",
    "    for col in ['gas', 'gasPrice', 'gasUsed', 'blockNumber']:\n",
    "        if col in df_clean.columns:\n",
    "            df_clean[col] = pd.to_numeric(df_clean[col], errors='coerce')\n",
    "    df_clean.dropna(subset=['value'], inplace=True)\n",
    "    return df_clean\n",
    "\n",
    "print(\"Loading and preprocessing data...\")\n",
    "df_processed = load_and_preprocess_data('data/compound_v2_v3_transactions.csv')\n",
    "if df_processed.empty:\n",
    "    print(\"Stopping execution due to missing data file.\")\n",
    "else:\n",
    "    print(f\"Data loaded. Shape: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0c09c4",
   "metadata": {},
   "source": [
    "### Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d3d38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating advanced wallet-level features...\n",
      "Processing features for 80 wallets using 'wallet_address' as identifier...\n",
      "Total wallets: 80\n",
      "Single-transaction wallets: 55\n",
      "Multi-transaction wallets: 25\n",
      "Keeping all wallets for analysis\n",
      "\n",
      "Key feature statistics:\n",
      "       total_transactions  avg_transaction_value  error_rate  \\\n",
      "count            80.00000                   80.0   80.000000   \n",
      "mean              3.46250                    0.0    0.005696   \n",
      "std               7.24428                    0.0    0.034331   \n",
      "min               1.00000                    0.0    0.000000   \n",
      "25%               1.00000                    0.0    0.000000   \n",
      "50%               1.00000                    0.0    0.000000   \n",
      "75%               2.00000                    0.0    0.000000   \n",
      "max              42.00000                    0.0    0.285714   \n",
      "\n",
      "       transaction_frequency  unique_recipients  contract_complexity  \n",
      "count              80.000000          80.000000            80.000000  \n",
      "mean                1.005187           1.250000             0.140165  \n",
      "std                 0.683637           0.646314             0.245053  \n",
      "min                 0.001692           1.000000             0.000000  \n",
      "25%                 1.000000           1.000000             0.000000  \n",
      "50%                 1.000000           1.000000             0.000000  \n",
      "75%                 1.000000           1.000000             0.333333  \n",
      "max                 4.000000           4.000000             0.794118  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_advanced_wallet_features(df):\n",
    "   \n",
    "    wallet_features_list = []\n",
    "    wallet_col = 'wallet_address' if 'wallet_address' in df.columns and df['wallet_address'].notna().any() else 'from'\n",
    "    all_wallets = df[wallet_col].dropna().unique()\n",
    "\n",
    "    print(f\"Processing features for {len(all_wallets)} wallets using '{wallet_col}' as identifier...\")\n",
    "    for i, wallet in enumerate(all_wallets):\n",
    "        if i > 0 and i % 1000 == 0:\n",
    "            print(f\"Processed {i} wallets...\")\n",
    "\n",
    "        wallet_txns = df[df[wallet_col] == wallet]\n",
    "        sent_txns = wallet_txns[wallet_txns['from'] == wallet] if 'from' in wallet_txns else pd.DataFrame()\n",
    "        received_txns = df[df['to'] == wallet] if 'to' in df else pd.DataFrame()\n",
    "\n",
    "        if len(wallet_txns) == 0: continue\n",
    "\n",
    "        features = {'wallet_id': wallet}\n",
    "        # BASIC & VALUE FEATURES\n",
    "        features['total_transactions'] = len(wallet_txns)\n",
    "        features['sent_transactions'] = len(sent_txns)\n",
    "        features['received_transactions'] = len(received_txns)\n",
    "        features['send_receive_ratio'] = len(sent_txns) / max(len(received_txns), 1)\n",
    "        features['total_value_sent'] = sent_txns['value'].sum()\n",
    "        features['total_value_received'] = received_txns['value'].sum()\n",
    "        features['avg_transaction_value'] = wallet_txns['value'].mean()\n",
    "        features['max_transaction_value'] = wallet_txns['value'].max()\n",
    "        features['value_std'] = wallet_txns['value'].std()\n",
    "        features['zero_value_ratio'] = (wallet_txns['value'] == 0).mean()\n",
    "\n",
    "        # GAS FEATURES\n",
    "        if 'gasUsed' in wallet_txns.columns and 'gasPrice' in wallet_txns.columns:\n",
    "            gas_costs = wallet_txns['gasUsed'] * wallet_txns['gasPrice']\n",
    "            features['avg_gas_used'] = wallet_txns['gasUsed'].mean()\n",
    "            features['total_gas_cost'] = gas_costs.sum()\n",
    "            features['error_rate'] = wallet_txns['isError'].mean() if 'isError' in wallet_txns else 0\n",
    "        else:\n",
    "            features['avg_gas_used'] = features['total_gas_cost'] = features['error_rate'] = 0\n",
    "\n",
    "        # TEMPORAL FEATURES\n",
    "        if len(wallet_txns) > 1:\n",
    "            time_sorted = wallet_txns.sort_values('timeStamp')\n",
    "            time_diffs = time_sorted['timeStamp'].diff().dt.total_seconds().dropna()\n",
    "            features['avg_time_between_txns_hr'] = time_diffs.mean() / 3600\n",
    "            activity_span_days = (time_sorted['timeStamp'].max() - time_sorted['timeStamp'].min()).days\n",
    "            features['activity_span_days'] = max(activity_span_days, 1)\n",
    "            features['transaction_frequency'] = len(wallet_txns) / features['activity_span_days']\n",
    "        else:\n",
    "            features['avg_time_between_txns_hr'] = 0\n",
    "            features['activity_span_days'] = 1\n",
    "            features['transaction_frequency'] = 1\n",
    "\n",
    "        # COUNTERPARTY & FUNCTION ANALYSIS \n",
    "        features['unique_recipients'] = sent_txns['to'].nunique() if len(sent_txns) > 0 else 0\n",
    "        features['unique_senders'] = received_txns['from'].nunique() if len(received_txns) > 0 else 0\n",
    "        features['recipient_concentration'] = len(sent_txns) / max(features['unique_recipients'], 1)\n",
    "        if 'functionName' in wallet_txns.columns:\n",
    "            features['unique_functions'] = wallet_txns['functionName'].nunique()\n",
    "            dominant_func_ratio = wallet_txns['functionName'].value_counts(normalize=True).iloc[0]\n",
    "            features['contract_complexity'] = 1 - dominant_func_ratio\n",
    "        else:\n",
    "            features['unique_functions'] = 0\n",
    "            features['contract_complexity'] = 0\n",
    "\n",
    "        wallet_features_list.append(features)\n",
    "\n",
    "    return pd.DataFrame(wallet_features_list)\n",
    "\n",
    "if not df_processed.empty:\n",
    "    \n",
    "    wallet_df = create_advanced_wallet_features(df_processed)\n",
    "    \n",
    "\n",
    "    wallet_df = wallet_df.fillna(0)\n",
    "    \n",
    "    \n",
    "    initial_count = len(wallet_df)\n",
    "    single_txn_wallets = (wallet_df['total_transactions'] == 1).sum()\n",
    "    \n",
    "    print(f\"Total wallets: {initial_count}\")\n",
    "    print(f\"Single-transaction wallets: {single_txn_wallets}\")\n",
    "    print(f\"Multi-transaction wallets: {initial_count - single_txn_wallets}\")\n",
    "    print(\"Keeping all wallets for analysis\")\n",
    "    \n",
    "   \n",
    "    print(\"\\nKey feature statistics:\")\n",
    "    key_features = ['total_transactions', 'avg_transaction_value', 'error_rate',\n",
    "                    'transaction_frequency', 'unique_recipients', 'contract_complexity']\n",
    "    available_key_features = [f for f in key_features if f in wallet_df.columns]\n",
    "    print(wallet_df[available_key_features].describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e30b6",
   "metadata": {},
   "source": [
    "### Advanced Risk Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ea4bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating advanced risk scores...\n",
      "Base risk score calculation complete.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_advanced_risk_score(df):\n",
    "    \"\"\"Calculate a sophisticated, weighted risk score.\"\"\"\n",
    "    feature_cols = [col for col in df.columns if col != 'wallet_id']\n",
    "    features = df[feature_cols].copy().replace([np.inf, -np.inf], 0)\n",
    "    scaler = MinMaxScaler()\n",
    "    features_scaled = pd.DataFrame(scaler.fit_transform(features), columns=feature_cols, index=features.index)\n",
    "\n",
    "    risk_components = {\n",
    "        'volume_risk': {'features': ['total_transactions', 'total_value_sent', 'max_transaction_value'], 'weight': 0.20},\n",
    "        'behavioral_risk': {'features': ['send_receive_ratio', 'recipient_concentration', 'transaction_frequency'], 'weight': 0.25},\n",
    "        'technical_risk': {'features': ['avg_gas_used', 'total_gas_cost', 'error_rate'], 'weight': 0.20},\n",
    "        'temporal_risk': {'features': ['avg_time_between_txns_hr'], 'weight': 0.15},\n",
    "        'diversity_risk': {'features': ['unique_recipients', 'unique_senders', 'unique_functions', 'contract_complexity'], 'weight': 0.20}\n",
    "    }\n",
    "    risk_scores = pd.DataFrame(index=df.index)\n",
    "    for component, config in risk_components.items():\n",
    "        available_features = [f for f in config['features'] if f in features_scaled.columns]\n",
    "        if available_features:\n",
    "            component_score = features_scaled[available_features].mean(axis=1)\n",
    "            risk_scores[component] = component_score * config['weight']\n",
    "        else:\n",
    "            risk_scores[component] = 0\n",
    "\n",
    "    base_score = risk_scores.sum(axis=1)\n",
    "   \n",
    "    if 'error_rate' in features_scaled: base_score[features_scaled['error_rate'] > 0.1] *= 1.3\n",
    "    if 'zero_value_ratio' in features_scaled: base_score[features_scaled['zero_value_ratio'] > 0.5] *= 1.2\n",
    "    if 'transaction_frequency' in features_scaled: base_score[features_scaled['transaction_frequency'] > 0.95] *= 1.4\n",
    "\n",
    "    return np.minimum(base_score * 1000, 1000)\n",
    "\n",
    "if not df_processed.empty:\n",
    "    print(\"Calculating advanced risk scores...\")\n",
    "    wallet_df['base_risk_score'] = calculate_advanced_risk_score(wallet_df)\n",
    "    print(\"Base risk score calculation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdd316f",
   "metadata": {},
   "source": [
    "### Anomaly Detection and Clustering for Score Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edfcda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying anomaly detection and clustering...\n",
      "Identified 4 anomalous wallets.\n",
      "Clustered wallets into 5 groups.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not df_processed.empty:\n",
    "    print(\"Applying anomaly detection and clustering...\")\n",
    "    feature_cols_anomaly = [col for col in wallet_df.columns if col not in ['wallet_id', 'base_risk_score']]\n",
    "    X = wallet_df[feature_cols_anomaly].fillna(0).replace([np.inf, -np.inf], 0)\n",
    "    X_scaled = StandardScaler().fit_transform(X)\n",
    "\n",
    "    # Isolation Forest for anomaly detection\n",
    "    iso_forest = IsolationForest(contamination=0.05, random_state=42, n_estimators=100)\n",
    "    wallet_df['is_anomaly'] = (iso_forest.fit_predict(X_scaled) == -1)\n",
    "\n",
    "    # K-means clustering for behavioral grouping\n",
    "    kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)\n",
    "    wallet_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    cluster_risk_adj = wallet_df.groupby('cluster')['base_risk_score'].mean() / wallet_df['base_risk_score'].mean()\n",
    "    wallet_df['cluster_risk_adjustment'] = wallet_df['cluster'].map(cluster_risk_adj)\n",
    "    print(f\"Identified {wallet_df['is_anomaly'].sum()} anomalous wallets.\")\n",
    "    print(f\"Clustered wallets into 5 groups.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151d083e",
   "metadata": {},
   "source": [
    "### Final Risk Score Calculation and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b2be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL RESULTS ===\n",
      "Total wallets analyzed: 80\n",
      "Average risk score: 128\n",
      "\n",
      "Top 5 highest risk wallets:\n",
      "                                     wallet_id  score\n",
      "0   0x0039f22efb07a647557c7c5d17854cfd6d489ef3   1000\n",
      "39  0x70d8e4ab175dfe0eab4e9a7f33e0a2d19f44001e   1000\n",
      "23  0x4814be124d7fe3b240eb46061f7ddfab468fe122   1000\n",
      "22  0x427f2ac5fdf4245e027d767e7c3ac272a1f40a65   1000\n",
      "57  0xa7f3c74f0255796fd5d3ddcf88db769f7a6bf46a    793\n",
      "\n",
      "Risk category distribution:\n",
      "risk_category\n",
      "Very Low     71\n",
      "Very High     4\n",
      "High          4\n",
      "Medium        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "✓ wallet_risk_scores.csv saved successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def calculate_final_risk_score(df):\n",
    "    \"\"\"Combines base score with anomaly and cluster adjustments.\"\"\"\n",
    "    final_scores = df['base_risk_score'].copy()\n",
    "    final_scores[df['is_anomaly']] *= 1.5 # Anomaly boost\n",
    "    final_scores *= df['cluster_risk_adjustment'] \n",
    "    return np.minimum(np.maximum(final_scores, 0), 1000).round(0).astype(int)\n",
    "\n",
    "if not df_processed.empty:\n",
    "    wallet_df['final_risk_score'] = calculate_final_risk_score(wallet_df)\n",
    "\n",
    "   \n",
    "    def categorize_risk(score):\n",
    "        if score < 200: return 'Very Low'\n",
    "        elif score < 400: return 'Low'\n",
    "        elif score < 600: return 'Medium'\n",
    "        elif score < 800: return 'High'\n",
    "        else: return 'Very High'\n",
    "    wallet_df['risk_category'] = wallet_df['final_risk_score'].apply(categorize_risk)\n",
    "\n",
    "    output_df = wallet_df[['wallet_id', 'final_risk_score']].copy()\n",
    "    output_df.columns = ['wallet_id', 'score']\n",
    "    output_df = output_df.sort_values('score', ascending=False)\n",
    "    output_df.to_csv('wallet_risk_scores.csv', index=False)\n",
    "\n",
    "    print(\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Total wallets analyzed: {len(output_df)}\")\n",
    "    print(f\"Average risk score: {output_df['score'].mean():.0f}\")\n",
    "    print(\"\\nTop 5 highest risk wallets:\")\n",
    "    print(output_df.head(5))\n",
    "    print(\"\\nRisk category distribution:\")\n",
    "    print(wallet_df['risk_category'].value_counts())\n",
    "    print(\"\\n✓ wallet_risk_scores.csv saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68df58b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88bb0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f02195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a164e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c85099c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dcdd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152055a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c15afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3accc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0cf29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98717064",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
